#!/usr/bin/env -S yue -e
-- TODO pick betweeen prototype and data as names and stick with one, heh
import "argparse"
import "inspect"
import "jsonschema"
import "unix"
import "rapidjson"
import "serpent"
import "ssl.https"
import "lib" as {
  :lsdir
  :run_cmd
  :string_split
  :table_get_path
  :table_deep_copy
  :table_insert_path
  :table_intersection
  :table_remove_path
  :table_shallow_copy
  :table_union
  :xdg_home_default
}
import "lib.semver" as semver
import "lib.luacheck" as {
  :ADDED_LUA_GLOBALS
  :INSTRUMENT_MODE_LUA_GLOBALS
  :PROTOTYPE_LUA_GLOBALS
  :PROTOTYPE_LUA_READ_ONLY_INDEXABLE_GLOBALS
  :PROTOTYPE_LUA_WRITE_INDEXABLE_GLOBALS
  :REMOVED_LUA_GLOBALS
  :RUNTIME_LUA_READ_ONLY_INDEXABLE_GLOBALS
  :RUNTIME_LUA_WRITE_INDEXABLE_GLOBALS
  :STD_LUACHECK_LUA52C
}

local *

API_BASE = "https://lua-api.factorio.com"
SCRIPT_DIR = do
  str = debug.getinfo(1, "S").source
  str\match "(.*)/"
CACHE_DIR = "#{xdg_home_default "cache"}/factorio-data-generation"
FACTORIO_DATA_DIR = "#{CACHE_DIR}/factorio-data"
FACTORIO_DATA_REPO_DIR = "#{CACHE_DIR}/factorio-data-repo"
JSON_DOCS_DIR = "#{CACHE_DIR}/json-docs"
DATA_DIR = "#{SCRIPT_DIR}/data"
LUA_DATA_DIR = "#{DATA_DIR}/lualib"
LUACHECKRC_DIR = "#{DATA_DIR}/luacheckrc"
RUNTIME_DOCS_DIR = "#{JSON_DOCS_DIR}/runtime-api"
PROTOTYPE_DOCS_DIR = "#{JSON_DOCS_DIR}/prototype-api"
SCHEMA_DIR = "#{SCRIPT_DIR}/schemas"
KNOWN_BUGGED_RUNTIME_DOC_VERSIONS = {
  "1.1.108": true
}
KNOWN_BUGGED_PROTOTYPE_DOC_VERSIONS = {
}
-- Some of the core mod's lualibs don't properly require() one another, we
-- document the missing entries here so we can properly lift values from them
-- in lift_core_lualib().
CORE_MOD_LUALIB_MISSED_REQUIRES = {
  "circuit-connector-sprites": { "util" }
}
-- Some of the core mod's lualibs aren't meant to be directly require()'d from
-- the outside, but only internally by other lualibs or toolling.
CORE_MOD_LUALIB_CANNOT_REQUIRE = {
  "circuit-connector-generated-definitions": true
  "builder": true
}
PROTOTYPE_LOADED_LUALIBS = {
  "util"
  "bonus-gui-ordering"
  "sound-util"
}
FIRST_VERSION_WITHOUT_MODULE = semver.new 2, 0, 0
FIRST_VERSION_WITH_RENAMED_STORAGE = semver.new 2, 0, 0
FIRST_VERSION_WITH_RUNTIME_DOCS = semver.new 1, 1, 35
FIRST_VERSION_WTIH_PROTOTYPE_DOCS = semver.new 1, 1, 89

main = ->
  doc_version_list = get_doc_versions!
  ensure_docs doc_version_list

  parser = argparse!
  with parser
    \name "factorio-data-generation"
    \description "A tool for generating useful data and configuration from Factorio (meta)data files"
    \command "latest-version"
    \command "luacheckrc"
    \command "extract-core-lualibs"
    \command "validate"
    \command_target "command"
    \require_command false

  args = parser\parse arg
  print "args: #{inspect args}"

  switch args.command
    -- TODO generic "update" command that invalidates the cached version list
    -- and runs the entire pipeline and TODO update the docs to mention it
    when "extract-core-lualibs"
      ensure_factorio_data!
      for version in *doc_version_list
        extract_core_lualibs version
    when "latest-version"
      most_recent_version = doc_version_list[#doc_version_list]
      print most_recent_version
    when "luacheckrc"
      generate_luacheckrc_files doc_version_list
    when "validate"
      validate_json_docs doc_version_list

  return


debug_print = (...) ->
  (os.getenv "DEBUG") and print(...)


get_doc_versions = ->
  unix.mkpath CACHE_DIR
  cached_file = "#{CACHE_DIR}/api-docs-version-list.html"
  ensure_url_downloaded API_BASE, cached_file
  with io.open cached_file, "r"
    html_str = \read "*a"
    \close!
    return parse_versions_html html_str


parse_versions_html = (html_str) ->
  -- Aww yeah, time to ~~parse~~scrape HTML with regex :V
  versions = [(semver.new major, minor, patch) for major, minor, patch in html_str\gmatch ">%s-(%d+)%.(%d+)%.(%d+)%s-<"]
  table.sort versions
  return [version for version in *versions when version >= FIRST_VERSION_WITH_RUNTIME_DOCS]


ensure_docs = (doc_version_list) ->
  unix.mkpath RUNTIME_DOCS_DIR
  unix.mkpath PROTOTYPE_DOCS_DIR
  for version in *doc_version_list
    cached_runtime_file = "#{RUNTIME_DOCS_DIR}/#{version}.json"
    ensure_url_downloaded "#{API_BASE}/#{version}/runtime-api.json", cached_runtime_file
    if version >= FIRST_VERSION_WTIH_PROTOTYPE_DOCS
      cached_prototype_file = "#{PROTOTYPE_DOCS_DIR}/#{version}.json"
      ensure_url_downloaded "#{API_BASE}/#{version}/prototype-api.json", cached_prototype_file

  return


ensure_factorio_data = () ->
  unless unix.stat FACTORIO_DATA_REPO_DIR
    cmd = "git clone --bare https://github.com/wube/factorio-data #{FACTORIO_DATA_REPO_DIR}"
    print "Fetching factorio-data repo: #{cmd}"
    run_cmd cmd
  else
    cmd = "git -C #{FACTORIO_DATA_REPO_DIR} fetch --all"
    print "Updating factorio-data repo: #{cmd}"
    run_cmd cmd

  cmd = "git -C #{FACTORIO_DATA_REPO_DIR} --no-pager tag --list"
  tag_fd = io.popen cmd, "r"
  versions = tag_fd\read "*a"
  versions = string_split versions, "\n"
  table.remove versions -- Remove trailing newline

  for version in *versions
    version_dir = "#{FACTORIO_DATA_DIR}/#{version}"
    continue if unix.stat version_dir
    unix.mkpath version_dir
    print "Checking out factorio-data for version #{version}"
    cmd = "git -C #{FACTORIO_DATA_REPO_DIR} archive #{version} | tar -x -C #{version_dir}"
    run_cmd cmd
  return


extract_core_lualibs = (version) ->
  data_dir = "#{FACTORIO_DATA_DIR}/#{version}"
  unless unix.stat data_dir
    print "#{version}: No factorio-data directory available for this version"
    return

  lualib_path = "#{data_dir}/core/lualib"
  lib_dir_files = lsdir lualib_path

  early_lib_set = {lib, false for lib in *PROTOTYPE_LOADED_LUALIBS}
  libraries = {}
  for child_path in *lib_dir_files
    libname = child_path\match "^(.+)%.lua$"
    continue unless libname
    -- These libs are loaded in the data phase by the core mod, get special handling >.>
    if early_lib_set[libname] != nil
      -- Track which early libs are present in this version
      early_lib_set[libname] = true
      continue
    libraries[]= libname
  table.sort libraries

  runtime_api_json = rapidjson.load "#{RUNTIME_DOCS_DIR}/#{version}.json"
  lua_data_dir = "#{LUA_DATA_DIR}/#{version}"
  unix.mkpath lua_data_dir

  early_new_globals = {}
  -- Gotta handle these first, as we need their global lists to exclude from others.
  -- This is because it's actually loaded by core mod's data stage, which is
  -- what we're using as the baseline to judge the other libs...
  early_libs = [lib for lib, present in pairs early_lib_set when present]
  for i, lib in ipairs early_libs
    table.insert libraries, i, lib
  for library in *libraries
    if CORE_MOD_LUALIB_CANNOT_REQUIRE[library]
      continue
    cached_file = "#{lua_data_dir}/#{library}.json"
    if unix.stat cached_file
      debug_print "#{version}: Already lifted library '#{library}'"
      continue
    print "#{version}: Lifting liibrary '#{library}'"

    sandbox_env = setup_sandbox_env runtime_api_json, data_dir

    baseline_global_env = if early_lib_set[library]
      -- Load the early lib without loading data stage, compare against no-data baseline
      table_deep_copy(sandbox_env)
    else
      data_stage_code_str = [[
      require("data.lua") -- Run the data stage for the core mod, ish
      return _G
      ]]

      sandbox_run, err = load data_stage_code_str, "factorio-data-generation.sandbox", "t", sandbox_env
      assert sandbox_run, err

      table_deep_copy(sandbox_run!)

    code_str = sandboxed_lualib_code_str library

    sandbox_run, err = load code_str, "factorio-data-generation.sandbox", "t", sandbox_env
    assert sandbox_run, err
    modified_global_env, loaded_module = sandbox_run!

    -- Strip recursive values & the data segment before comparing
    baseline_global_env._G = nil
    baseline_global_env.package.loaded = nil
    baseline_global_env.data = nil
    modified_global_env._G = nil
    modified_global_env.package.loaded = nil
    modified_global_env.data = nil

    new_globals = diff_table_paths baseline_global_env, modified_global_env

    table.sort new_globals
    if early_lib_set[library]
      for g in *new_globals
        early_new_globals[g] = true
    else
      new_globals = [g for g in *new_globals when early_new_globals[g] == nil]

    local loaded_module_returns
    if loaded_module
      library_module_name = library\gsub "-", "_"
      loaded_module_returns = extract_table_namespace loaded_module, "#{library_module_name}."
      table.sort loaded_module_returns

    -- Options here are to ensure multi-line, stably-sorted JSON files so they're more git-friendly
    rapidjson.dump {:new_globals, :loaded_module_returns, :library}, cached_file, { pretty: true, sort_keys: true }
  return

LIFT_CORE_LUALIB_FORMAT_STR = [[
local mod = require("%s")
return _G, mod
]]
sandboxed_lualib_code_str = (lualib) ->
  if extra_requires := CORE_MOD_LUALIB_MISSED_REQUIRES[lualib]
    str = ""
    for req in *extra_requires
      str ..= "local #{req} = require(\"#{req}\")\n"
    str ..= string.format LIFT_CORE_LUALIB_FORMAT_STR, lualib
    return str
  else
    return string.format LIFT_CORE_LUALIB_FORMAT_STR, lualib

diff_table_paths = (baseline, other, prefix="") ->
  new_globals = {}
  for k, v in pairs other
    -- Don't care about array values, skip 'em
    continue if (type k) == "number"
    if (type v) == "table"
      -- Recurse to handle table children
      children = if baseline
        diff_table_paths baseline[k], v, "#{prefix}#{k}."
      else
        diff_table_paths nil, v, "#{prefix}#{k}."
      for child in *children
        new_globals[]= child
    if baseline == nil or baseline[k] == nil
      new_globals[]= "#{prefix}#{k}"
  return new_globals

extract_table_namespace = (t, prefix="") ->
  names = {}
  for k, v in pairs t
    -- Don't care about array values, skip 'em
    continue if (type k) == "number"
    names[] = "#{prefix}#{k}"
    if (type v) == "table"
      -- Recurse to handle table children
      for child in *(extract_table_namespace v, "#{prefix}#{k}.")
        names[] = child
  return names

-- Prepare a sandboxed environment similar to Factorio's own
-- Technically we should be using Lua 5.2 w/ LUA_COMPAT_ALL, but in practice it
-- does not seem to matter.
setup_sandbox_env = (runtime_api_json, data_dir) ->
  stage_globals = build_runtime_globals runtime_api_json
  sandbox_env = {
    ...stage_globals
    -- :_G
    :_VERSION
    :arg
    :assert
    :bit32
    :collectgarbage
    -- :coroutine
    -- :debug
    -- :dofile
    :error
    :getmetatable
    -- :io
    :ipairs
    -- :load
    -- :loadfile
    :math
    :next
    -- :os
    -- :package
    :pairs
    :pcall
    :print
    :rawequal
    :rawget
    :rawlen
    :rawset
    -- :require
    :select
    :setmetatable
    -- :string
    -- :table
    :tonumber
    :tostring
    :type
    :xpcall
  }
  sandbox_env._G = sandbox_env
  -- Not a runtime stage global, but a data stage global that is used by some
  -- of the lualibs for some versions.
  sandbox_env.data = {
    extend: (self, otherdata) ->
      if type(otherdata) ~= "table" or #otherdata == 0
        error("Invalid prototype array " .. serpent.block(otherdata, {maxlevel: 1}))

      for e in *otherdata
        unless e.type
          error("Missing type in the following prototype definition " .. serpent.block(e))
        unless e.name
          error("Missing name in the following prototype definition " .. serpent.block(e))

        t = self.raw[e.type]
        if t == nil
          t = {}
          self.raw[e.type] = t
        t[e.name] = e
    raw: {}
    is_demo: false
  }
  sandbox_env.debug = { getinfo: debug.getinfo, traceback: debug.traceback }
  sandbox_env.load = (ld, source, _, env=sandbox_env) ->
    load ld, source, "t", env

  sandbox_env.loadstring = sandbox_env.load
  sandbox_env.serpent = require "serpent"
  sandbox_env.storage = {}
  sandbox_env.string = table_shallow_copy string
  compat53 = require "compat53.module"
  sandbox_env.string.pack = compat53.string.pack
  sandbox_env.string.packsize = compat53.string.packsize
  sandbox_env.string.unpack = compat53.string.unpack
  sandbox_env.table = table_shallow_copy table
  isinteger = (n) ->
    assert type n == "number", "isinteger only takes numerical values as input, not: #{n}"
    {_, fractional} = math.modf n
    return fractional == 0
  sandbox_env.table.maxn = (t) ->
    math.max table.unpack [k for k, _ in pairs t when type k == "number" and isinteger k]
  sandbox_env.table.pairs_concat = (t) -> table.concat [v for _, v in pairs t]
  sandbox_env.unpack = table.unpack

  -- Rewrite require()
  sandbox_env.package = { loaded: {} }
  sandbox_env.require = (path) ->
    if sandbox_env.package.loaded[path]
      return sandbox_env.package.loaded[path]

    current_mod = 'core'
    search_path = { "#{data_dir}/core/lualib" } -- Core's lualib is always in the search path
    assert (path\match "%.%.") == nil, "Cannot use '..' in require() paths"
    sub_path = if (path\sub 1, 2) == '__'
      -- Load from other mod root
      other_mod, sub_path = path\match "^__(.-)__%.(.+)$"
      assert other_mod != nil, "Invalid mod-reference path in require: #{path}"
      search_path[]= "#{data_dir}/#{other_mod}"
      sub_path
    else
      -- Load relative to mod root
      search_path[]= "#{data_dir}/#{current_mod}"
      path

    if (sub_path\sub -4) == ".lua"
      sub_path = sub_path\sub 1, sub_path\len! - 4

    sub_path = sub_path\gsub "%.", "/"
    for dir_path in *search_path
      file_path = "#{dir_path}/#{sub_path}.lua"
      if unix.stat file_path
        fd, err = io.open file_path, "r"
        assert fd != nil, "error loading module `#{path}' (#{err})"
        file_str = fd\read "*a"
        fd\close!
        func, err = sandbox_env.load file_str, path
        assert func != nil, "error loading module `#{path}' (#{err})"
        mod = func!
        sandbox_env.package.loaded[path] = mod
        return mod

    error "module `#{path}' not found: ", 2

  return sandbox_env


-- Stub just enough of the runtime global variables and functions that we can
-- load Factorio's lualibs and dump their structure
build_runtime_globals = (runtime_api_json) ->
  defines = build_lua_defines runtime_api_json.defines
  globals = { :defines }

  if runtime_api_json.global_functions
    for {:name} in *runtime_api_json.global_functions
      switch name
        when "localised_print"
          globals.localised_print = (...) -> print (inspect ...)
        when "log"
          globals.log = (...) -> print ...
        when "table_size"
          globals.table_size = (t) ->
            count = 0
            for _, _ in pairs t
              count += 1
            count
        else
          error "Have not written an implementation for global_function #{name}"

  classes = {}
  for class_attr in *runtime_api_json.classes
    {:name, :methods, :attributes, :operators} = class_attr
    class_ = {}
    for method in *methods
      class_[method.name] = -> nil
    for attribute in *attributes
      class_[attribute.name] = {}
    mt = {}
    has_ops = false
    for operator in *operators
      switch operator.name
        when "call"
          has_ops = true
          mt.__call = -> nil
        when "index"
          has_ops = true
          mt.__index = -> nil
        when "length"
          has_ops = true
          mt.__len = -> nil
        else
          error "Have not written an implementation for operator #{operator.name}"
    if has_ops
      setmetatable class_, mt
    classes[name] = class_

  for obj in *runtime_api_json.global_objects
    globals[obj.name] = classes[obj.type]

  return globals

build_lua_defines = (defines_json) ->
  lua_defines = {}
  for { :name, :values, :subkeys } in *defines_json
    if values
      lua_define = {}
      lua_defines[name] = lua_define
      -- Enum-like, assign arbitrary incrementing values
      i = 0
      for value in *values
        i += 1
        lua_define[value.name] = i
    else if subkeys
      -- Tree-like, recurse
      sub_defines = build_lua_defines subkeys
      lua_defines[name] = sub_defines
    else
      debug_print "value-less define: #{name}"
      lua_defines[name] = 1
  return lua_defines


generate_luacheckrc_files = (versions) ->
  unix.mkpath LUACHECKRC_DIR
  for version in *versions
    luacheckrc_path = "#{LUACHECKRC_DIR}/#{version}.lua"
    if unix.stat luacheckrc_path
      print "#{version}: Existing luacheckrc output file, not overwriting"
      continue
    else if not unix.stat "#{LUA_DATA_DIR}/#{version}"
      print "#{version}: Skipping, no lualib directory to extract from"
      continue
    else
      print "#{version}: Building luacheckrc output file"
    runtime_api_json = rapidjson.load "#{RUNTIME_DOCS_DIR}/#{version}.json"

    -- Include core-mod's `util`, `bonus-gui-ordering`, and `sound-util`
    -- libraries as part of the accessible globals during the prototype stage, as
    -- these are loaded by the core-mod at that point, and the prototype stage
    -- uses a single shared Lua state for all mods.
    lualibs_set = {lib, true for lib in *PROTOTYPE_LOADED_LUALIBS}
    lualib_data_stage_globals = populate_lualib_globals version, lualibs_set
      |> global_paths_to_luacheckrc

    runtime_stage_defines = extract_luacheckrc_defines runtime_api_json
    runtime_stage_dynamic_globals, global_functions = extract_luacheckrc_json_api_globals runtime_api_json
    -- The data stage shares the same global_functions as the runtime stage,
    -- they're just not in its API docs
    data_stage_global_funcs = {read_globals: global_functions }

    -- Populate the feature_flags mapping, if present
    local feature_flag_globals
    for {:name, :attributes} in *runtime_api_json.classes
      found = false
      continue if name != "LuaBootstrap"
      for attribute in *attributes
        continue if attribute.name != "feature_flags"
        feature_flag_globals = {name, {} for {:name} in *attribute.read_type.parameters}
        found = true
        break
      break if found
    feature_flag_globals = { read_globals: { feature_flags: { fields: feature_flag_globals }} }

    -- Populate from our manual lists of non-machine-documented extra globals
    added_globals = global_paths_to_luacheckrc ADDED_LUA_GLOBALS
    prototype_added_globals = global_paths_to_luacheckrc PROTOTYPE_LUA_GLOBALS

    removed_lua_globals = REMOVED_LUA_GLOBALS
    if version >= FIRST_VERSION_WITHOUT_MODULE
      removed_lua_globals[]= "module"

    -- Mush it all together, adding in the Lua 5.2 LUA_COMPAT_ALL baseline, then
    -- removing that needs to be removed. Ideally we could just use luacheck's
    -- lua52c standard and add the remove list to `not_globals` in our std, but
    -- `not_globals` is not supported within standards
    data_stage_new_globals = table_union STD_LUACHECK_LUA52C,
                                         added_globals,
                                         prototype_added_globals,
                                         feature_flag_globals,
                                         runtime_stage_defines,
                                         data_stage_global_funcs,
                                         lualib_data_stage_globals
                             |> remove_global_paths_from_luacheckrc REMOVED_LUA_GLOBALS

    runtime_stage_new_globals = table_union STD_LUACHECK_LUA52C,
                                            added_globals,
                                            runtime_stage_defines,
                                            runtime_stage_dynamic_globals
                             |> remove_global_paths_from_luacheckrc REMOVED_LUA_GLOBALS


    -- We also mmanually patch a few relevant, documented things that can't be
    -- determined automatically from the data or lualib extractions
    make_indexable = (t) -> t.other_fields = true
    make_indexable_writable = (t) ->
      t.other_fields = true
      t.read_only = false
    data_stage_new_globals = data_stage_new_globals
      |> modify_luacheckrc_paths PROTOTYPE_LUA_READ_ONLY_INDEXABLE_GLOBALS, make_indexable
      |> modify_luacheckrc_paths PROTOTYPE_LUA_WRITE_INDEXABLE_GLOBALS, make_indexable_writable

    storage_name = if version >= FIRST_VERSION_WITH_RENAMED_STORAGE
      "storage"
    else
      "global"
    write_indexable_globals = [storage_name, ...RUNTIME_LUA_WRITE_INDEXABLE_GLOBALS]

    runtime_stage_new_globals = runtime_stage_new_globals
      |> modify_luacheckrc_paths RUNTIME_LUA_READ_ONLY_INDEXABLE_GLOBALS, make_indexable
      |> modify_luacheckrc_paths write_indexable_globals, make_indexable_writable

    instrument_mode_globals = global_paths_to_luacheckrc INSTRUMENT_MODE_LUA_GLOBALS

    factorio_min_globals = table_intersection data_stage_new_globals, runtime_stage_new_globals
    -- TODO add per-lualib extension standards, and update readme
    luacheckrc =
      stds:
        factorio_data_stage: data_stage_new_globals
        factorio_control_stage: runtime_stage_new_globals
        factorio_instrument_mode: instrument_mode_globals
        factorio_min: factorio_min_globals

    -- Options here are to ensure multi-line, stably-sorted JSON files so they're more git-friendly
    with assert(io.open luacheckrc_path, "w", "Couldn't open #{luacheckrc_path} for writing")
      \write "return "
      \write serpent.serialize luacheckrc, {indent: "  ", sortkeys: true, sparse: true}
      \close!


populate_lualib_globals = (version, restrict_libs_to=nil) ->
  lualib_dir = "#{LUA_DATA_DIR}/#{version}"
  lualib_globals = {}
  -- Include core-mod's `util`, `bonus-gui-ordering`, and `sound-util`
  -- libraries as part of the accessible globals during the prototype stage, as
  -- these are loaded by the core-mod at that point, and the prototype stage
  -- uses a single shared Lua state for all mods.
  lualibs = {}
  lib_dir_files = lsdir lualib_dir
  for child_path in *lib_dir_files
    libname = child_path\match "^(.+)%.json$"
    continue unless libname
    continue if restrict_libs_to and restrict_libs_to[libname] == nil
    lualibs[]= libname
    lualib_json = rapidjson.load "#{lualib_dir}/#{libname}.json"
    for path in *lualib_json.new_globals
      lualib_globals[path] = true
  lualib_globals = strip_lax_globals lualibs, lualib_globals
  lualib_globals = [k for k, _ in pairs lualib_globals]
  return lualib_globals


-- Remove entries for the libraries/global objects themselves, if they have any
-- children, e.g. `util` but not `util.mul_shift` or `tons`
strip_lax_globals = (bases, globals_set) ->
  -- Convert names appropriately
  bases = [base\gsub "-", "_" for base in *bases]
  has_children = {}
  for global_path, _ in pairs globals_set
    for lib in *bases
      continue if has_children[lib]
      if global_path\match "^#{lib}%."
        has_children[lib] = true

  return {lib, v for lib, v in pairs globals_set when has_children[lib] != true}


extract_luacheckrc_defines = (api_json) ->
  processing = [{define, {"read_globals", "defines", "fields"}} for define in *api_json.defines]
  defines_luacheckrc = {}
  while next_ := table.remove processing
    {define, path} = next_
    {:name, :values, :subkeys} = define
    table.insert path, name
    table_insert_path defines_luacheckrc, path, {}
    table.insert path, "fields"
    if values
      -- Enum-like values, just add as-is
      for value in *values
        table.insert path, value.name
        table_insert_path defines_luacheckrc, path, {}
        table.remove path
      table.remove path
    if subkeys
      -- Tree-like, needs to be handled as its own define on a deeper path
      for child in *subkeys
        sub_path = table_deep_copy path
        table.insert processing, {child, sub_path}
  return defines_luacheckrc


INDEXABLE_COMPLEX_TYPES = { t, true for t in *{"array", "dictionary", "LuaCustomTable", "table", "tuple"}}
extract_luacheckrc_json_api_globals = (runtime_api_json) ->
  luacheckrc = {}
  luacheckrc.read_globals = {}
  global_functions = {}

  if runtime_api_json.global_functions
    for {:name} in *runtime_api_json.global_functions
      luacheckrc.read_globals[name] = {}
      global_functions[name] = {}
  else
    -- Older runtime APIs don't have it, so populate from this fixed list
    global_functions =
      localised_print: {}
      log: {}
      table_size: {}
    luacheckrc.read_globals = table_deep_copy global_functions

  -- global_objects are class references, resolve them
  classes = {class_.name, class_ for class_ in *runtime_api_json.classes}
  global_objects = {obj.name, classes[obj.type] for obj in *runtime_api_json.global_objects}

  -- Types can be a complex_type, or string reference to a: basic type, Class,
  -- Concept, or Define

  -- Concepts are either a Type, or a special complex_type with just: { type:
  -- "builtin" }, and the actual table encoded in the name of the concept
  concepts = {concept.name, concept for concept in *runtime_api_json.concepts}

  basic_types = {}
  if runtime_api_json.builtin_types
    -- Older API versions didn't track it in the concepts, but as its own top-level opject
    for {:name} in *runtime_api_json.builtin_types
      basic_types[name] = true
  else
    basic_types = {concept.name, true for concept in *runtime_api_json.concepts when concept.type and concept.type.complex_type and concept.type.complex_type == "builtin"}
  -- NOTE: 'bool' is used once instead of 'boolean' in at least one API JSON
  -- doc; this is probably a bug in the data but we need to account for it
  basic_types.bool = true

  processing = [{obj, {"read_globals", name}} for name, obj in pairs global_objects]
  while next_ := table.remove processing
    {obj, path} = next_
    {:methods, :attributes} = obj
    table_insert_path luacheckrc, path, {}
    table.insert path, "fields"
    if methods
      for method in *methods
        table.insert path, method.name
        table_insert_path luacheckrc, path, {}
        table.remove path
    if attributes
      -- Class attributes are Types.
      for attr in *attributes
        table.insert path, attr.name
        attr_block = {}
        table_insert_path luacheckrc, path, attr_block
        -- Determine if the attribute can be indexed, can be written to, etc.,
        -- and if any further changes are needed as a result

        if attr.write_type or attr.write == false
          attr_block.read_only = false

        -- There's plenty of infinite recursion possible here, so just go
        -- three levels deep, e.g. game.player.activate_paste.
        -- Ideally we'd be dynamically looking up things instead, but we'd need
        -- a proper LSP for that... something to think about.
        recurse = #path < 6

        type_ = attr.type or attr.read_type or attr.write_type

        -- Concepts are just a level of Type indirection with extra documentation
        if concepts[type_]
          type_ = concepts[type_]

        -- Handle another form of Type indirection
        if type_.complex_type == "type"
          type_ = type_.value

        if (type type_) == "string"
          if basic_types[type_]
            if type_ == "table"
              attr_block.other_fields = true
          -- Check for class reference
          else if classes[type_]
            if recurse
              sub_path = table_deep_copy path
              table.insert processing, {classes[type_], sub_path}
            else
              attr_block.other_fields = true
          else if (type_\match "^defines%.") == nil
            -- If it's not a Define, NFI what else it could be at this point
            error "Unhandled type value: #{type_}"
        else
          if INDEXABLE_COMPLEX_TYPES[type_.complex_type]
            attr_block.other_fields = true
        table.remove path

      table.remove path

  return luacheckrc, global_functions


-- Convert set of 'serpent.serialize' paths to a strict read_globals luacheckrc
-- configuration block
global_paths_to_luacheckrc = (global_paths) ->
  luacheckrc_globals = {}
  for str_path in *global_paths
    path = string_split str_path, "."
    cur = luacheckrc_globals
    for i, path_element in ipairs path
      cur[path_element] = {} unless cur[path_element]
      if i != #path
        cur[path_element].fields = {} unless cur[path_element].fields
        cur = cur[path_element].fields

  return {read_globals: luacheckrc_globals}


remove_global_paths_from_luacheckrc = (luacheckrc, global_paths) ->
  global_paths = [global_path_to_luacheckrc_path path for path in *global_paths]
  for path in *global_paths
    table_remove_path luacheckrc, path
  return luacheckrc


global_path_to_luacheckrc_path = (global_path) ->
  path = string_split global_path, "."
  res = {"read_globals"}
  for i, path_element in ipairs path
    res[]= path_element
    res[]= "fields" if i != #path
  return res


modify_luacheckrc_paths = (luacheckrc, paths, fn) ->
  for path in *paths
    block = get_luacheckrc_path luacheckrc, path
    fn block
  return luacheckrc


get_luacheckrc_path = (luacheckrc, path) ->
  path = global_path_to_luacheckrc_path path
  return table_get_path luacheckrc, path


validate_json_docs = (versions) ->
  runtime_validators, prototype_validators = initialise_json_schema_validators!
  print "Validating machine-readable runtime API docs against JSON Schemas"
  for version in *versions
    runtime_api_json = rapidjson.load "#{RUNTIME_DOCS_DIR}/#{version}.json"
    runtime_validator = runtime_validators[runtime_api_json.api_version]
    if runtime_validator
      valid, err = runtime_validator runtime_api_json
      if valid
        print "runtime #{version}: valid"
      else
        if KNOWN_BUGGED_RUNTIME_DOC_VERSIONS[tostring version]
          print "runtime #{version}: invalid: known issue, the JSON from this version is bugged, see #{SCHEMA_DIR}/runtime-api-docs-bugs.md"
        else
          print "runtime #{version}: invalid"
        print err

  for version in *versions
    continue unless version >= FIRST_VERSION_WTIH_PROTOTYPE_DOCS
    prototype_api_json = rapidjson.load "#{PROTOTYPE_DOCS_DIR}/#{version}.json"
    prototype_validator = prototype_validators[prototype_api_json.api_version]
    if prototype_validator
      valid, err = prototype_validator prototype_api_json
      if valid
        print "prototype #{version}: valid"
      else
        if KNOWN_BUGGED_PROTOTYPE_DOC_VERSIONS[tostring version]
          print "prototype #{version}: invalid: known issue, the JSON from this version is bugged, see #{SCHEMA_DIR}/prototype-api-docs-bugs.md"
        else
          print "prototype #{version}: invalid"
        print err


initialise_json_schema_validators = ->
  print "Parsing JSON Schemas"
  schema_files = lsdir SCHEMA_DIR
  runtime_validators = {}
  prototype_validators = {}
  for name in *schema_files
    version = name\match "^runtime%-api%-docs%-v(%d+)%.json$"
    if version
      schema_json = rapidjson.load "#{SCHEMA_DIR}/#{name}"
      runtime_validators[tonumber version] = jsonschema.generate_validator schema_json, { null: rapidjson.null }
    else
      version = name\match "^prototype%-api%-docs%-v(%d+)%.json$"
      continue unless version
      schema_json = rapidjson.load "#{SCHEMA_DIR}/#{name}"
      prototype_validators[tonumber version] = jsonschema.generate_validator schema_json, { null: rapidjson.null }

  return runtime_validators, prototype_validators


ensure_url_downloaded = (url, path) ->
  if unix.stat path
    debug_print "Already have file downloaded at #{path}"
  else
    print "Fetching url #{url}"
    res, code, _, status = https.request url
    assert res, "Failed to fetch url (#{url}), code: #{code}, status: #{status}"
    with io.open path, "w"
      \write res
      \close!


main!
return
